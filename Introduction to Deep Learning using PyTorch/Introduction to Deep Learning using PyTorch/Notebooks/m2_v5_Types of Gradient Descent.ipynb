{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat_sum</th>\n",
       "      <th>hs_gpa</th>\n",
       "      <th>fy_gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>464</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sat_sum  hs_gpa  fy_gpa\n",
       "0      508    3.40    3.18\n",
       "1      488    4.00    3.33\n",
       "2      464    3.75    3.25\n",
       "3      380    3.75    2.42\n",
       "4      428    4.00    2.63"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "data = pd.read_csv('Prodigy University Dataset.csv')\n",
    "# Split the data into features (X) and target (y)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Converting data to numpy\n",
    "X = data[['sat_sum', 'hs_gpa']].values\n",
    "# reshape the fy_gpa into a 2D array with [data_size] rows and 1 column\n",
    "y = data['fy_gpa'].values.reshape(-1, 1)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the features so that it is easier to train the data\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Convert numpy to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model with 2 neurons\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propagation\n",
    "preds = model(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1223],\n",
       "        [0.1129],\n",
       "        [0.0293],\n",
       "        [0.1440],\n",
       "        [0.0043]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9385, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculating Loss\n",
    "criterion = MSELoss()\n",
    "loss = criterion(preds, y_train_tensor)\n",
    "print(loss)\n",
    "# to learners: You may get different values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing predictions on X_train with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1223],\n",
       "        [0.1129],\n",
       "        [0.0293],\n",
       "        [0.1440],\n",
       "        [0.0043]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000],\n",
       "        [3.1100],\n",
       "        [1.6300],\n",
       "        [3.0200],\n",
       "        [1.5500]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2010, -0.5799],\n",
       "        [ 0.1211,  0.3072]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3010,  0.5979]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all the cells above till here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization and Backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2010, -0.5799],\n",
       "        [ 0.1211,  0.3072]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2991,  0.6007]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Training:\n",
      "Train Loss: 9.6453, Test Loss: 9.9598\n"
     ]
    }
   ],
   "source": [
    "# performance on train  and test sets  before training\n",
    "train_loss = criterion(model(X_train_tensor), y_train_tensor).item()\n",
    "test_loss = criterion(model(X_test_tensor), y_test_tensor).item()\n",
    "print(f'Without Training:\\nTrain Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7091],\n",
       "        [-0.6832],\n",
       "        [-0.4896],\n",
       "        [-0.6274],\n",
       "        [-0.5459]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at predictions\n",
    "model(X_train_tensor)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.7475, Test Loss: 0.8321\n",
      "Epoch 2: Train Loss: 0.5839, Test Loss: 0.6454\n",
      "Epoch 3: Train Loss: 0.5049, Test Loss: 0.5622\n",
      "Epoch 4: Train Loss: 0.4530, Test Loss: 0.5094\n",
      "Epoch 5: Train Loss: 0.4184, Test Loss: 0.4717\n",
      "Epoch 6: Train Loss: 0.3955, Test Loss: 0.4496\n",
      "Epoch 7: Train Loss: 0.3803, Test Loss: 0.4325\n",
      "Epoch 8: Train Loss: 0.3698, Test Loss: 0.4225\n",
      "Epoch 9: Train Loss: 0.3622, Test Loss: 0.4166\n",
      "Epoch 10: Train Loss: 0.3575, Test Loss: 0.4113\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "# Execute the training loop\n",
    "for epoch in range(10):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = criterion(model(X_train_tensor), y_train_tensor).item()\n",
    "    # print(epoch,': ', train_loss)\n",
    "    test_loss = criterion(model(X_test_tensor), y_test_tensor).item()\n",
    "    print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3234],\n",
       "        [2.3198],\n",
       "        [2.1826],\n",
       "        [2.5166],\n",
       "        [2.0564]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at predictions\n",
    "model(X_train_tensor)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialising model weights\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss: 3.2054, Test Loss: 3.4044\n",
      "Epoch 200: Train Loss: 2.0763, Test Loss: 2.2405\n",
      "Epoch 300: Train Loss: 1.4520, Test Loss: 1.5896\n",
      "Epoch 400: Train Loss: 1.1067, Test Loss: 1.2242\n",
      "Epoch 500: Train Loss: 0.9136, Test Loss: 1.0159\n",
      "Epoch 600: Train Loss: 0.8025, Test Loss: 0.8935\n",
      "Epoch 700: Train Loss: 0.7353, Test Loss: 0.8179\n",
      "Epoch 800: Train Loss: 0.6915, Test Loss: 0.7679\n",
      "Epoch 900: Train Loss: 0.6605, Test Loss: 0.7322\n",
      "Epoch 1000: Train Loss: 0.6365, Test Loss: 0.7047\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=800, shuffle=True) #800 is the number of samples in train set\n",
    "# Execute the training loop\n",
    "for epoch in range(1000): # increasing the epochs for effective training\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0: # printing after every 100 epochs\n",
    "        train_loss = criterion(model(X_train_tensor), y_train_tensor).item()\n",
    "        # print(epoch,': ', train_loss)\n",
    "        test_loss = criterion(model(X_test_tensor), y_test_tensor).item()\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialising model weights\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(2, 1)\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 0.5837, Test Loss: 0.6660\n",
      "Epoch 100: Train Loss: 0.4364, Test Loss: 0.4916\n",
      "Epoch 150: Train Loss: 0.4097, Test Loss: 0.4620\n",
      "Epoch 200: Train Loss: 0.3913, Test Loss: 0.4431\n",
      "Epoch 250: Train Loss: 0.3780, Test Loss: 0.4301\n",
      "Epoch 300: Train Loss: 0.3685, Test Loss: 0.4210\n",
      "Epoch 350: Train Loss: 0.3618, Test Loss: 0.4146\n",
      "Epoch 400: Train Loss: 0.3569, Test Loss: 0.4102\n",
      "Epoch 450: Train Loss: 0.3534, Test Loss: 0.4071\n",
      "Epoch 500: Train Loss: 0.3510, Test Loss: 0.4052\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_data, batch_size= 64, shuffle=True) #800 is the number of samples in train set\n",
    "# Execute the training loop\n",
    "for epoch in range(500): # increasing the epochs for effective training\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0: # printing after every 100 epochs\n",
    "        train_loss = criterion(model(X_train_tensor), y_train_tensor).item()\n",
    "        # print(epoch,': ', train_loss)\n",
    "        test_loss = criterion(model(X_test_tensor), y_test_tensor).item()\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
