Introduction to Prompt Engineering:
===================================

![image](https://github.com/user-attachments/assets/33e75c06-0eeb-4d21-a517-adead3310501)

  - in previous module , we learned about prompt enggineering and why it is important.
  - we also interacted with CHATGPT using its interface.
  - however the interface has limitations.
![image](https://github.com/user-attachments/assets/f9b51af7-fc03-4823-bcea-8b7ac2b9b349)

  - As it **only allows interaction** with CHAATGPT and **retrieving response it is not possible**.

  - hence it is not feasible to integrate with application in an automated manner.
  - when developing llm with prompt engineering   , it is essential to have flexibility to prompt
    CHATGPT and retrieve response directly in to our applications so that you can work on it.
![image](https://github.com/user-attachments/assets/6c007e7b-7ce4-404a-ae9e-24586232a0a1)

  - that is where , this is made possible by Application program interface(API).
  - API makes easier for developers to use specific features or access data from one application to another.
  - openAI provides chatGPT api for developers , **allowing users to send prompt** and **retrieve responses
    regularly**.
