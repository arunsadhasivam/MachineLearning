Hinglish Instruct Finetuning using LoRA
=========================================

Instruction Fine tuning using LORA:
===================================

Supervise fine tune or instruct fine tune and we use open hathi model on a small instruct dataset.
- openhathi is a open source model developed on top of llama for bilingual  hindi and english.
- conversation in hindi and english.

Step 1: setup env:
==================
![image](https://github.com/user-attachments/assets/f0834634-4926-4c96-a2fe-2a498f755ab3)


Step 2: data Processing:
========================

  - open hathi 7 billion parameter model datatset is english self instruct v0 dataset
    that has been synthetically generated by gpt.
  - load tokenizer using llama tokenizer.pretrain()
  - we use template
  - preprocess function -> takes the batch of sample each having converstation to which
    apply the chat template and return in the content column.
  - load dataset , dataset name , then transform in to mapping function.
    pass the preprocess function to it. we pass multiple sample or batch of sample
    during each call . remove all existing column from the dataset.

    ![image](https://github.com/user-attachments/assets/81b81ab8-816b-4517-b137-561859c406b1)
![image](https://github.com/user-attachments/assets/f1daf050-7207-48fc-aab5-09bd5c8ccd22)


Step 3: Create PEFT MOdel:
===========================

![image](https://github.com/user-attachments/assets/4ec97ca2-3e76-434c-b1de-2e4622e8b609)

  - lora_alpha=16, scaling factor (16/2)
  - lora_dropout = 0.1 
  ![image](https://github.com/user-attachments/assets/2a1426e0-8004-4ead-877f-5a363fb7e8ec)


open hathi model

![image](https://github.com/user-attachments/assets/a5e0eb44-5938-4a33-ad30-3ffd064444c4)

Step 4: Training:
=======================
![image](https://github.com/user-attachments/assets/1d0214da-d417-407c-97e9-2aa0b67bc10a)
![image](https://github.com/user-attachments/assets/abfab986-4445-4a94-a8a1-5872bdbe70e5)
- As you can see in chart training loss is going down.

![image](https://github.com/user-attachments/assets/fa6aef07-5645-473f-8336-bb14b87d3e0b)

![image](https://github.com/user-attachments/assets/28000796-2514-410b-b90a-69839b171ead)

  - it consumes less gpu memory than tiny llama model.


Step 5: load the trained model:
=================================


![image](https://github.com/user-attachments/assets/05b39d7c-d422-4e93-bcf2-0e0247822de8)

![image](https://github.com/user-attachments/assets/eb703b45-85ec-43fa-883d-f7c0e4c1f43d)

   - load the fine tune PEFT model by using the PEFTmodel.frompretrain(). first
     get the fine tune PEFT config and then load pretrain base model and then
     load tokenizer , resize model to account for new special token and
     then load fine tune PEFT model using PEFTmodel.frompretrain() by giving
     base model and path to the fine tuned PEFT model.


  ![image](https://github.com/user-attachments/assets/e52a3f70-8d0b-48aa-99e3-5d51aea516d3)
 
As you can see result in hindi.

memory
======

  - memory occupied during fine tuning 14 gb.

![image](https://github.com/user-attachments/assets/5d505c9b-d549-47d7-a576-4f2080edf342)


     
