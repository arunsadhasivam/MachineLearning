Ethical Consideration:
======================
![image](https://github.com/user-attachments/assets/a8f4a751-1027-4337-8ab4-ff7f5eb95f47)

     - take an look at the some of issues like copyright and legal issues.
     

1.copyright and legal issues:
==============================
![image](https://github.com/user-attachments/assets/bf1ca2c1-b62a-4488-ac9e-853883a0ef8e)

    - considering copyright and legal issues.
    - genAI learn from extensive online data including public and sometimes certain protected content.
    - using such data can cause infrightment on copyright laws.
      for e.g if it generates content similar to any book protected by author then cause copyright issues.
    - this might results in legal action.

2.intellectual property concerns:
==================================
![image](https://github.com/user-attachments/assets/75808f0c-e08b-4339-a787-3e50a01cf0cf)

   - training data is basically all data from internet for llm and visual models.
   - consider visual models like dalle , meg-journey was trained on millions of public images.
   - ip challenges: resemblences to existence works questions ownership rights.
   - for e.g some images like some other images of origin author causes issue like who is owner of this 
     images.
  -  legal implications like incited IP debates , court cases

3.data privacy violation:
==========================

![image](https://github.com/user-attachments/assets/ac750706-7168-43c1-903c-e83d2feb9d38)

 - fast public datasets including social media and digital conversation across variety of social media
   platforms have been used to train some of these models.
 - some times these data can have sensitive information, and thus possess privacy risk, where the potential
   for the unintended exposure of personal data such as usernames,passwords and more.
 - for e.g above the chatgpt license key , which chatgpt generates and it worked which is not good.
   although it is fixed but it is real problem in past.
![image](https://github.com/user-attachments/assets/5f9ad661-65cc-4b09-982d-dc387c10eae9)

 - so this is why it is important not exposing sensitive information to gen AI .
 - privacy concerns have prompted organization like openAI to intensify efforts to preventing training gen AI  models
   on sensitive data including PII.

4.Uninted legal and social consequence:
========================================
![image](https://github.com/user-attachments/assets/15d1df30-6cae-4d82-8715-e5a38f4faf7c)
![image](https://github.com/user-attachments/assets/e1600998-1295-431e-a5c7-176ee17f7c8d)
![image](https://github.com/user-attachments/assets/d0a07e59-fc23-4365-b550-0a0ac8d7dea1)

    - bias in data lead to lot of issues including the industry restrictions where ai applications are used
     in content generations , interviewing and testing.
    - source ambiguity in information, sometimes it gives source information some times it can give the 
      source information. some time it does have information what is source of information.
    - cite quotations are being generated by llm that can raise ethical concerns.
    - bias mitigation, like bias in facial recognition , it is bias on generating female faces with dark skill content.
    - so need right content data in training to avoid bias.
    - larger percentage of error in detecting female with dark skin because it is not trained properly.

5.Biases and hallunications:
=============================

![image](https://github.com/user-attachments/assets/6747a66b-9f9e-4991-9ffc-97df402865b5)

![image](https://github.com/user-attachments/assets/e0e56703-0f26-4f9e-976f-217639b32cc7)

  - advance pattern completers and data generators they dont understand fully meaning like human.
  - reflective bias in training dataset can skew ai content.
  - content accuracy - vulnerability to hallunications can lead to erroneous output.
  - as you can gemini could not able generate image of pope.
  - you should not put all images , since pope are in vatican city certain become pope.
  - having control over right kind of data, right kind of training
  - also should have guardrails and moderations in generative response from llm
     are critical to keep in mind whenever you are building genAI applications.
  
  -
