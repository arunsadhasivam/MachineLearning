Indexing and Retriever:
======================


![image](https://github.com/user-attachments/assets/1a6dd687-0e75-4200-962e-28f75072e598)

![image](https://github.com/user-attachments/assets/925678e1-852b-45b9-af61-eb903e19c2c7)

**Node** - Represent the information present in chunk of document.
**indexing** - indexing component executes the entire data ingestion process like chunking,dataingestion,creating
embedding as a pipeline.


<p>
<details><summary> 1.Index</summary></details>
  


Index:
======

- structured dataset enabling fast and efficient information retrieval.
- Allows quick location and retrieval of information.
- improves the generation process by accessing  a large corpus efficiently.


why do we need index in a RAG System:
======================================

1) **Efficiency**: Enables quick retrieval by organizing data for efficient searches.
2) **Scalability**: Handles large-scale datasets, ensuring timely retrieval operations.
3) **Accuracy**: improves retrieval precision, enhancing response quality.
4) **Real-time**: Performance: supports fast, real-time responses for applications like chatbots
   and virtual assistants.
   
IndexTypes:
============

index types supported by llamaIndex

![image](https://github.com/user-attachments/assets/dc63d219-2f51-4d73-81bd-3a953513fb58)



1) **Summary Index**- stores and retrieves condesed summary of document.
2) **VectorStore Index**:- Stores and retrieves high dimensional representations of semantic similarity searches.
3) **Document Summary Index:** -Manages and retrieves summary of entire document.
4) **TreeIndex**  -  Organize data hierarchially and range query
5) **KeywordTableIndex**- utilizes traditional keyword based search to retrieve documents based on keyword.


</p>
</details>




<p>
<details><summary>2.Retrieval</summary></details>


  Retrieval:
  ===========
  
  
  ![image](https://github.com/user-attachments/assets/4828c193-dd3c-425a-915e-b825a6e44d3b)
  
  
  Different Types of Retrievers:
  ==============================
  
  Retriever depends on specific indexing technique.
  
  Retrieval Modes:
  ===============
  
  ![image](https://github.com/user-attachments/assets/46bee7ed-b69f-4415-b1ac-7b12c40c7523)

</p>
</details>


<p>
<details><summary>1.summary Index Retriever</summary></details>



1)summary Index:
================

![image](https://github.com/user-attachments/assets/e107a2c2-1ea3-42a5-81b4-c18dd187c16b)

- summary index takes document break in to chunk and stores as chunk.
- stores these chunk as a chain.
- use various retrieval modes
  ![image](https://github.com/user-attachments/assets/3328b2c7-fa7d-4c2e-9cbc-1251874eb0c0)


  1.1) Summary Index Retriever:
  =============================
  
     ![image](https://github.com/user-attachments/assets/518fdbd7-c3c3-4ec4-91ab-5f8a7a9087ec)

   -  During the retriever state, if no other query parameters are passed , LLamaIndex index
      Simply loads all the nodes in to a list and passes to response synthesis module for generating reply.
   -  The summary index retriever retrieves the summary information from the summary index based on
      simple key word or term based search.
   - This retriever is good for straight forward query with keyword matching is sufficient to find
     relevant summary.
   - This has advantage for fast and efficient for basic retrieval task.
 
   1.2) Summary Index Embedding Retriever:
   =========================================

    ![image](https://github.com/user-attachments/assets/fc9a9bd7-2094-4056-9721-ae755a4708e4)

    - Based on **Node and query Embeddings**. This retriever compares the query embeddings with the summary
      Embeddings to retrieve the most relevant summary based on **semantic** similarity.
    - This Retriever is suitable for complex query require semantic understanding. This retriever
       is very accurate and contextually relevant in terms of retriever.
    - Similary instead of Embeddings, can also use LLM as mode.
    - SummaryIndexLLMRetriever employes a LLM could generate embeddings or directly score summaries
      based on query.
    - LLM provides the deep contextual understading allowing for more nuance and accurate retriever.
    - This retriever offers the higher developed contextual accuracy and relevance by leveraging the
      power of LLM.
      
  
    
    
</p>
</details>



<p>
<details><summary>2.Vector Store Index  Retriever</summary></details>

  2)Vector Store Index  Retriever:
 =========================================

    ![image](https://github.com/user-attachments/assets/fd4afddf-2ff9-4551-aa3b-684339170834)


    - Most Frequent type of index we encounter.
    - Vector Store INdex takes a document and breaks in to multiple chunks and stores each chunk as a node.
    - it then creates a vector embeddings of the text present in each of node and stores in to that node.
    - finally all these nodes are stored in the vector DB.
    - Vector Index has only one retriever Mode i.e **Vector Store INdex Retriever**.
    - During retriever state, the vector store index retriever takes the query of user and the vector
      store index **post** and **fetches the top-k  similar nodes from the index** and passes that to the
      response synthesis module.
    - **Response synthesis module** defines how to generate the answer from the top-k similar nodes.

  2.1)Vector Store Index vs summary Index:
 ==========================================

   - Summary Index stores all the nodes in the form of the sequence/list in the storage , unlike the
     vector storage index.
   - Embeddings are created during the querying time rather than during index construction itself.

 2.2)Limiations of VectorStore and SUmmary index
 ========================================================

  ![image](https://github.com/user-attachments/assets/a22f0ff5-b07c-4638-bd55-e73a336582fe)
  ![image](https://github.com/user-attachments/assets/b9349c00-4da2-4387-9b9e-3a2436222f40)
  ![image](https://github.com/user-attachments/assets/7815d3bd-9ba5-4ce1-baab-2b767ebd7248)


  **1.Vector Store Index**:
     -powerfull for semantic searches. it is computationally intensive
      since it deals with high dimensional vector operations.it might requires significant
      storage space especially for large datasets.

  **2.Summary Index** :
    - only provides summary , might miss detail information.
    - Less effective for understanding the full context of large documents.


  **3.Document Summary Index** :
     - **Balanced Approach** - combines summary efficiency with detailed context.
     - **contextual Retrieval** - Extract nuanced information efficiently.
     - **Enhanced Detail** : provides richer insights from large documents.
     - **Optimal Efficiency**: Fast retrieval with comprehensive content.
    
</p>
</details>



<p>
<details><summary>3.Document Summary Index Retriever Modes</summary></details>

![image](https://github.com/user-attachments/assets/c9473276-ad20-45a5-9390-4406978249ad)

**LLM Based retrieval:** - This approach leverage llm to accesss the summarizes of the document and data relevance to query.
and then assign relevance score to each of document. this benefits from the llm capabilities to understand the
meaning and context within the summarizes lead to more accurate selection of data points.


**Embedding Based retrieval:** - This approach utilize the embedding techniques - compare the query embeddings
to the embeddings of document summary to identify relevant document.
This approach provides faster retrieval retrieval compared to llm .
however it might be less nuance in understanding the intricacies of language with in the summary.

NOTE:
====

1) llm based prioritize accuracy and comprehension.
2) Embedding might offer faster data retrieval.

</p>
</details>




<p>
<details><summary>4.Keyword Table Index Retriever Modes</summary></details>


</p>
</details>
