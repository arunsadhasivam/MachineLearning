Recap:
======


  - Overview of LLMOPS
  - AWS Sagemaker for datascients-
    1) whole cloud setups ,
    2) introduced with sagemaker
    3) createad our own domain and jupyter lab setup necessary for whole course
  - Module 3 - Langchain for continuous integration.
    1) saw traditional method of managing and researching with LLMs is not efficient enough
    2) how we can leverage langchain to modularize our code
    3) use lot of prebuilt features that langchain provides
  - Module 4- Langfuse for CICD
    1) not just disccussed langfuse for monitoring application end-end
    2) but also other features such as datasets, run, playground and evaluations that we can use in our applications
       to further monitor and observe the user behaviour and how the application is doing in production.
  - Module 5 - Sagemaker pipelines
    1) fine tune the given LLM module on particular datasets
    2) then once the fine tune and training is successfull, we see different types of deployment in sagemaker
    3) Automated the whole process end - to end in sagemaker pipelines
    4) Also , discussed some more additional features that sagemaker pipelines provides us.
  - Module 6 - continuous deployment
    1) how continuous deployment should be done
    2) what are the different ways to do these deployments to further optimize on speed,cost and scale.
  - Module 7- kubernetes
    1) kubernetes popular and widely used tool for container orchestration.
    2) how we use kubernetes to deploy LLM applications.
  - Module 8 - Real world testing
    1) Real world testing using kubernetes deployment along with horizondal POD autoscaler that we enabled.
    2) and with that real world testing , we were confident that the deployment that we did is actually performing
       the way it performs for real world scenarios


Summary:
=========

  - All about LLMOps course, these tools and frameworks will help you in tackling issues related to training,
    deployment , scaling and monitoring.
    
