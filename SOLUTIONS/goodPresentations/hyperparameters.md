Supervised Learning Algorithms: 

1Ô∏è‚É£ Linear Regression: Used for predicting a continuous dependent variable based on one or more independent variables. 
2Ô∏è‚É£ Logistic Regression: Used for binary classification problems where the outcome is a categorical variable. 
3Ô∏è‚É£ Naive Bayes: Based on Bayes' theorem, it is used for classification tasks, particularly text classification. 
4Ô∏è‚É£ Decision Tree: A tree-like model used for both classification and regression tasks, which splits data into branches to make predictions. 
5Ô∏è‚É£ Random Forest: An ensemble method that uses multiple decision trees to improve accuracy and prevent overfitting. 
6Ô∏è‚É£ Gradient Boosted Trees: An ensemble technique that builds models sequentially, with each new model correcting errors made by the previous ones.

üìà Unsupervised Learning Algorithms: 

1Ô∏è‚É£ Principal Component Analysis (PCA): A dimensionality reduction technique used to reduce the number of variables in a dataset while retaining as much information as possible. 
2Ô∏è‚É£ K-Means Clustering: A clustering algorithm that partitions data into K distinct clusters based on similarity.

üîç Instance-Based Learning: 

1Ô∏è‚É£ K-Nearest Neighbors (KNN): A simple, instance-based learning algorithm used for classification and regression tasks. It predicts the label of a data point based on the labels of its nearest neighbors.

ü§ñ Deep Learning: 

1Ô∏è‚É£ Dense Neural Network: A type of artificial neural network where each neuron is connected to every neuron in the previous and next layer. Used for a wide range of tasks, including image and speech recognition.

![1751343538248](https://github.com/user-attachments/assets/520b7dad-2ffb-4e7b-91f6-eaf784989ce1)
