{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a8b793",
   "metadata": {
    "id": "28a8b793"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/finetuning/embeddings/finetune_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551753b7-6cd2-4f81-aec0-da119e4705ad",
   "metadata": {
    "id": "551753b7-6cd2-4f81-aec0-da119e4705ad"
   },
   "source": [
    "# Finetune Embeddings\n",
    "\n",
    "In this notebook, we show users how to finetune their own embedding models.\n",
    "\n",
    "We go through three main sections:\n",
    "1. Preparing the data (our `generate_qa_embedding_pairs` function makes this easy)\n",
    "2. Finetuning the model (using our `SentenceTransformersFinetuneEngine`)\n",
    "3. Evaluating the model on a validation knowledge corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a23e114-c210-4b1f-b2e7-c05e30b7414e",
   "metadata": {},
   "source": [
    "<b> If you face any errors in running this notebook, you run the code mentioned in the below link in the google colab <b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d89d5-847c-43ac-a8c9-b28a468eb666",
   "metadata": {},
   "source": [
    "https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7446d0-3b44-41c1-a2e0-6275837e358f",
   "metadata": {},
   "source": [
    "pip install llama-index-finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99afd542-fc47-44ac-aed0-b3684108dba5",
   "metadata": {
    "id": "99afd542-fc47-44ac-aed0-b3684108dba5"
   },
   "source": [
    "## Generate Corpus\n",
    "\n",
    "First, we create the corpus of text chunks by leveraging LlamaIndex to load some financial PDFs, and parsing/chunking into plain text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9280d438-b6bd-4ccf-a730-7c8bb3ebdbeb",
   "metadata": {
    "id": "9280d438-b6bd-4ccf-a730-7c8bb3ebdbeb"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.schema import MetadataMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c42620",
   "metadata": {
    "id": "73c42620"
   },
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee52df4-da88-4042-bbcf-c7c893658498",
   "metadata": {},
   "source": [
    "download the 'uber_10k' and 'lyft_10k' data files from the below links and move them into the folder that contains this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d059e-fb7c-400c-ba4e-fb177585e7dd",
   "metadata": {
    "id": "d8e11b0c",
    "outputId": "64027a63-a47a-42b9-8adb-d771a0752f5b"
   },
   "source": [
    "https://github.com/run-llama/llama_index/blob/9607a05a923ddf07deee86a56d386b42943ce381/docs/docs/examples/data/10k/uber_2021.pdf\n",
    "https://github.com/run-llama/llama_index/blob/9607a05a923ddf07deee86a56d386b42943ce381/docs/docs/examples/data/10k/lyft_2021.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e890bc-557b-4d3c-bede-3e80dfeeee18",
   "metadata": {
    "id": "c5e890bc-557b-4d3c-bede-3e80dfeeee18"
   },
   "outputs": [],
   "source": [
    "TRAIN_FILES = [\"./lyft_2021.pdf\"]\n",
    "VAL_FILES = [\"./uber_2021.pdf\"]\n",
    "\n",
    "TRAIN_CORPUS_FPATH = \"./data/train_corpus.json\"\n",
    "VAL_CORPUS_FPATH = \"./data/val_corpus.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1da871c1-9d58-467a-92fd-06ed3d94534b",
   "metadata": {
    "id": "1da871c1-9d58-467a-92fd-06ed3d94534b"
   },
   "outputs": [],
   "source": [
    "def load_corpus(files, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Loading files {files}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(input_files=files)\n",
    "    docs = reader.load_data()\n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "    parser = SimpleNodeParser.from_defaults()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Parsed {len(nodes)} nodes\")\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53056d8b-3b4c-4364-9b07-a375aa84330b",
   "metadata": {
    "id": "53056d8b-3b4c-4364-9b07-a375aa84330b"
   },
   "source": [
    "We do a very naive train/val split by having the Lyft corpus as the train dataset, and the Uber corpus as the val dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3651c77-d085-4fbc-bb34-61f143ad6674",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "15ef5e0c899d48be9a7f6da0c642a798",
      "564db8b32b274a428edc854878721a72"
     ]
    },
    "id": "d3651c77-d085-4fbc-bb34-61f143ad6674",
    "outputId": "71676cc3-2c69-4f71-909d-881ba44c62f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files ['./lyft_2021.pdf']\n",
      "Loaded 238 docs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9529822528c5425aa23338922f6fb2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 341 nodes\n",
      "Loading files ['./uber_2021.pdf']\n",
      "Loaded 307 docs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fef1dd38954b7ea2131f9ff377e689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 406 nodes\n"
     ]
    }
   ],
   "source": [
    "train_nodes = load_corpus(TRAIN_FILES, verbose=True)\n",
    "val_nodes = load_corpus(VAL_FILES, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4482c48-844b-448b-9552-3f38b455645c",
   "metadata": {
    "id": "b4482c48-844b-448b-9552-3f38b455645c"
   },
   "source": [
    "### Generate synthetic queries\n",
    "\n",
    "Now, we use an LLM (gpt-3.5-turbo) to generate questions using each text chunk in the corpus as context.\n",
    "\n",
    "Each pair of (generated question, text chunk used as context) becomes a datapoint in the finetuning dataset (either for training or evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "580334ce-ddaa-4cc0-8c3e-7294d11e4d2f",
   "metadata": {
    "collapsed": true,
    "id": "580334ce-ddaa-4cc0-8c3e-7294d11e4d2f",
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PydanticCustomError",
     "evalue": "Invalid python path: No module named 'pydantic.deprecated.decorator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_validators.py:87\u001b[0m, in \u001b[0;36m_import_string_logic\u001b[0;34m(dotted_path)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydantic.deprecated.decorator'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_validators.py:50\u001b[0m, in \u001b[0;36mimport_string\u001b[0;34m(value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_validators.py:96\u001b[0m, in \u001b[0;36m_import_string_logic\u001b[0;34m(dotted_path)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pydantic.deprecated.decorator'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPydanticCustomError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_qa_embedding_pairs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/finetuning/__init__.py:13\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     EmbeddingQAFinetuneDataset,\n\u001b[1;32m      8\u001b[0m     generate_qa_embedding_pairs,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     SentenceTransformersFinetuneEngine,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientFinetuneEngine\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIFinetuneEngine\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrerankers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere_reranker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     CohereRerankerFinetuneEngine,\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/finetuning/gradient/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientFinetuneEngine\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientFinetuneEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/finetuning/gradient/base.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, overload\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLLMFinetuneEngine\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientModelAdapterLLM\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGradientFinetuneEngine\u001b[39;00m(BaseLLMFinetuneEngine):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         workspace_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/gradient/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBaseModelLLM, GradientModelAdapterLLM\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientBaseModelLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientModelAdapterLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/gradient/base.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Sequence\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gradient\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     ChatMessage,\n\u001b[1;32m      6\u001b[0m     CompletionResponse,\n\u001b[1;32m      7\u001b[0m     CompletionResponseGen,\n\u001b[1;32m      8\u001b[0m     LLMMetadata,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbridge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, PrivateAttr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata \u001b[38;5;28;01mas\u001b[39;00m _metadata\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m _metadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradientai\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, CapabilityFilterOption\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gradient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gradient\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Guidance, Model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/_base_model.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model_adapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelAdapter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/_model.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Literal, Optional, TypedDict\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyncio_threads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_thread \u001b[38;5;28;01mas\u001b[39;00m _asyncio_to_thread\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomplete_model_body_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     CompleteModelBodyParams,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompleteResponse\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/openapi/client/__init__.py:19\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Gradient AI API\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Do not edit the class manually.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# import apis into sdk package\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlocksApi\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingsApi\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/openapi/client/api/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# import apis into api package\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlocksApi\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingsApi\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/openapi/client/api/blocks_api.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_arguments, ValidationError\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annotated\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrictBytes, StrictStr, constr\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/__init__.py:374\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_migration.py:287\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(name)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_validators.py:52\u001b[0m, in \u001b[0;36mimport_string\u001b[0;34m(value)\u001b[0m\n",
      "\u001b[0;31mPydanticCustomError\u001b[0m: Invalid python path: No module named 'pydantic.deprecated.decorator'"
     ]
    }
   ],
   "source": [
    "from llama_index.finetuning import generate_qa_embedding_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef43fe59-a29c-481b-b086-e98e55016d3e",
   "metadata": {
    "id": "ef43fe59-a29c-481b-b086-e98e55016d3e",
    "outputId": "11691c3c-21a9-4dbd-ce46-5fa1a946a1bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 349/349 [11:24<00:00,  1.96s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [14:54<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = generate_qa_embedding_pairs(train_nodes)\n",
    "val_dataset = generate_qa_embedding_pairs(val_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93aec8-5276-49e8-baef-f60235cb05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.save_json(\"train_dataset.json\")\n",
    "val_dataset.save_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54e453cc-4c14-407e-a8a1-c3a06a9228b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "743f163c-25df-4c18-9abe-05052b034d70",
   "metadata": {
    "id": "743f163c-25df-4c18-9abe-05052b034d70"
   },
   "outputs": [],
   "source": [
    "# [Optional] Load\n",
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b60a2e06-d70b-41dc-b1a7-42795e420260",
   "metadata": {
    "id": "b60a2e06-d70b-41dc-b1a7-42795e420260",
    "outputId": "2766c596-7132-46f7-e50c-a43337c2e86a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the information provided, how many shares of Class A common stock and Class B common stock did Lyft, Inc. have outstanding on February 22, 2022?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.queries.values())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62368cb8-a303-48b1-8429-5e3655abcc3b",
   "metadata": {
    "id": "62368cb8-a303-48b1-8429-5e3655abcc3b"
   },
   "source": [
    "## Run Embedding Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1d08066-5f00-48f1-b12a-e80bc193d4c0",
   "metadata": {
    "id": "c1d08066-5f00-48f1-b12a-e80bc193d4c0",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PydanticCustomError",
     "evalue": "Invalid python path: No module named 'pydantic.deprecated.decorator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_validators.py:87\u001b[0m, in \u001b[0;36m_import_string_logic\u001b[0;34m(dotted_path)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydantic.deprecated.decorator'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_validators.py:50\u001b[0m, in \u001b[0;36mimport_string\u001b[0;34m(value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_validators.py:96\u001b[0m, in \u001b[0;36m_import_string_logic\u001b[0;34m(dotted_path)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pydantic.deprecated.decorator'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPydanticCustomError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformersFinetuneEngine\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/finetuning/__init__.py:13\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     EmbeddingQAFinetuneDataset,\n\u001b[1;32m      8\u001b[0m     generate_qa_embedding_pairs,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     SentenceTransformersFinetuneEngine,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientFinetuneEngine\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIFinetuneEngine\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrerankers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere_reranker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     CohereRerankerFinetuneEngine,\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/finetuning/gradient/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientFinetuneEngine\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientFinetuneEngine\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/finetuning/gradient/base.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, overload\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinetuning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLLMFinetuneEngine\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientModelAdapterLLM\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGradientFinetuneEngine\u001b[39;00m(BaseLLMFinetuneEngine):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m         workspace_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/gradient/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBaseModelLLM, GradientModelAdapterLLM\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientBaseModelLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradientModelAdapterLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/gradient/base.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, Sequence\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gradient\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     ChatMessage,\n\u001b[1;32m      6\u001b[0m     CompletionResponse,\n\u001b[1;32m      7\u001b[0m     CompletionResponseGen,\n\u001b[1;32m      8\u001b[0m     LLMMetadata,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbridge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, PrivateAttr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata \u001b[38;5;28;01mas\u001b[39;00m _metadata\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m _metadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradientai\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, CapabilityFilterOption\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gradient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gradient\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Guidance, Model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/_base_model.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model_adapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelAdapter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/_model.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Literal, Optional, TypedDict\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyncio_threads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_thread \u001b[38;5;28;01mas\u001b[39;00m _asyncio_to_thread\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomplete_model_body_params\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     CompleteModelBodyParams,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompleteResponse\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/openapi/client/__init__.py:19\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    Gradient AI API\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Do not edit the class manually.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# import apis into sdk package\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlocksApi\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingsApi\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/openapi/client/api/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# import apis into api package\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocks_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlocksApi\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingsApi\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradientai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelsApi\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gradientai/openapi/client/api/blocks_api.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_arguments, ValidationError\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annotated\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrictBytes, StrictStr, constr\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/__init__.py:374\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_migration.py:287\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(name)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_validators.py:52\u001b[0m, in \u001b[0;36mimport_string\u001b[0;34m(value)\u001b[0m\n",
      "\u001b[0;31mPydanticCustomError\u001b[0m: Invalid python path: No module named 'pydantic.deprecated.decorator'"
     ]
    }
   ],
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26625ab5-ddc9-4dbd-9936-39b69c6a7cdc",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "cac8b16ac8f74fdc9b881b5ffc5c31f9",
      "3986867ebce44086a636bb543046805d",
      "fea463ec47974745a0c4721babc7de95",
      "2130d3f7b58947649b2dc096da3b25d6",
      "bc87380cd84a42ffa8448acd784a7492",
      "6cb0e9a054b249a3a1d8e2b572f1539e",
      "fc2ffca6c32a4bf8a9b9b52096da6cac",
      "af5c76b2ad90448d9a6b65c122abdcc1",
      "5aa977961092498c93f6dfdbf8576f8b",
      "05ea15f90ddd4966a83a3f20e7f26cbe",
      "638ddd027e8542bb8156ca36d0b48db6",
      "befc300b48da4fabb7dd7304cdde214a",
      "8a33b5877cd14fad8d773c61eae60b22"
     ]
    },
    "id": "26625ab5-ddc9-4dbd-9936-39b69c6a7cdc",
    "outputId": "9d847aed-8c77-495b-9ed9-b008878eff51"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac8b16ac8f74fdc9b881b5ffc5c31f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)421f3/.gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3986867ebce44086a636bb543046805d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea463ec47974745a0c4721babc7de95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)93c10421f3/README.md:   0%|          | 0.00/90.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2130d3f7b58947649b2dc096da3b25d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)c10421f3/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc87380cd84a42ffa8448acd784a7492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb0e9a054b249a3a1d8e2b572f1539e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2ffca6c32a4bf8a9b9b52096da6cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5c76b2ad90448d9a6b65c122abdcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa977961092498c93f6dfdbf8576f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ea15f90ddd4966a83a3f20e7f26cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)421f3/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638ddd027e8542bb8156ca36d0b48db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befc300b48da4fabb7dd7304cdde214a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)93c10421f3/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a33b5877cd14fad8d773c61eae60b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)10421f3/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    train_dataset,\n",
    "    model_id=\"BAAI/bge-small-en\",\n",
    "    model_output_path=\"test_model\",\n",
    "    val_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad99e6-dd9d-485a-86e9-1845cf51802b",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "7dbc03b853514f4480fbdb41ab5f1e8c",
      "9298054a85c542b1855a3ae631114945",
      "6d0a19bd54d74714ba38acc8cc107aee"
     ]
    },
    "id": "28ad99e6-dd9d-485a-86e9-1845cf51802b",
    "outputId": "69e75c82-4b0f-47be-ef86-4855df8bfddb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbc03b853514f4480fbdb41ab5f1e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9298054a85c542b1855a3ae631114945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0a19bd54d74714ba38acc8cc107aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a2ba2-e7e6-4025-8887-cac6e7ecb493",
   "metadata": {
    "id": "467a2ba2-e7e6-4025-8887-cac6e7ecb493"
   },
   "outputs": [],
   "source": [
    "embed_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828dd6fe-9a8a-419b-8663-56d81ce73774",
   "metadata": {
    "id": "828dd6fe-9a8a-419b-8663-56d81ce73774"
   },
   "source": [
    "## Evaluate Finetuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a66b83-4cbb-4374-a632-0f1bb2b785ab",
   "metadata": {
    "id": "f4a66b83-4cbb-4374-a632-0f1bb2b785ab"
   },
   "source": [
    "In this section, we evaluate 3 different embedding models:\n",
    "1. proprietary OpenAI embedding,\n",
    "2. open source `BAAI/bge-small-en`, and\n",
    "3. our finetuned embedding model.\n",
    "\n",
    "We evaluate the models using **hit rate** metric\n",
    "\n",
    "We show that finetuning on synthetic (LLM-generated) dataset significantly improve upon an opensource embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57d5176f-1f21-4bcb-adf5-da1c4cccb8d3",
   "metadata": {
    "id": "57d5176f-1f21-4bcb-adf5-da1c4cccb8d3"
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.schema import TextNode\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4c2b8-1ad8-420c-83d2-b88e0519895d",
   "metadata": {
    "id": "dda4c2b8-1ad8-420c-83d2-b88e0519895d"
   },
   "source": [
    "### Define eval function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c24d3-3d72-4ce8-94a4-2da9c1b2605c",
   "metadata": {
    "id": "398c24d3-3d72-4ce8-94a4-2da9c1b2605c"
   },
   "source": [
    "**Option 1**: We use a simple **hit rate** metric for evaluation:\n",
    "* for each (query, relevant_doc) pair,\n",
    "* we retrieve top-k documents with the query,  and\n",
    "* it's a **hit** if the results contain the relevant_doc.\n",
    "\n",
    "This approach is very simple and intuitive, and we can apply it to both the proprietary OpenAI embedding as well as our open source and fine-tuned embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89401d3-a157-4f96-86d4-212e631a54bc",
   "metadata": {
    "id": "b89401d3-a157-4f96-86d4-212e631a54bc"
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    dataset,\n",
    "    embed_model,\n",
    "    top_k=5,\n",
    "    verbose=False,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
    "    index = VectorStoreIndex(\n",
    "        nodes, embed_model=embed_model, show_progress=True\n",
    "    )\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
    "\n",
    "        eval_result = {\n",
    "            \"is_hit\": is_hit,\n",
    "            \"retrieved\": retrieved_ids,\n",
    "            \"expected\": expected_id,\n",
    "            \"query\": query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d33dd-c39f-4c05-8adc-65db12163c88",
   "metadata": {
    "id": "af2d33dd-c39f-4c05-8adc-65db12163c88"
   },
   "source": [
    "### Run Evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630aa25-2395-4a8b-83cf-2885fbc862f4",
   "metadata": {
    "id": "c630aa25-2395-4a8b-83cf-2885fbc862f4"
   },
   "source": [
    "#### OpenAI\n",
    "\n",
    "Note: this might take a few minutes to run since we have to embed the corpus and queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0784f-415e-4d3a-8c88-757b28b9e5df",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "3de7bb1fc4d541a2beb27e33dcdb6557",
      "2d063690aa0e4b8180c0877e0e25e316"
     ]
    },
    "id": "61a0784f-415e-4d3a-8c88-757b28b9e5df",
    "outputId": "c58e6956-1595-4997-d728-27c86e78c455"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de7bb1fc4d541a2beb27e33dcdb6557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d063690aa0e4b8180c0877e0e25e316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_model = OpenAIEmbedding(model='text-embedding-3-small')\n",
    "val_results = evaluate(val_dataset, embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc73212-fc53-48c1-b347-f5ee3a29ae82",
   "metadata": {
    "id": "ccc73212-fc53-48c1-b347-f5ee3a29ae82"
   },
   "outputs": [],
   "source": [
    "df_opanai = pd.DataFrame(val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb61bb-c287-40fe-b3c7-bbfc2d2b1b94",
   "metadata": {
    "id": "25eb61bb-c287-40fe-b3c7-bbfc2d2b1b94",
    "outputId": "1f1a88f9-a099-4d8b-8fda-6de0a1c8b1a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8969555035128806"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate = df_opanai[\"is_hit\"].mean()\n",
    "hit_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd6c62-65a8-4f72-a67c-d0d62c92d7d1",
   "metadata": {
    "id": "a1bd6c62-65a8-4f72-a67c-d0d62c92d7d1"
   },
   "source": [
    "### BAAI/bge-small-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24454aeb-9e3e-4954-ab70-647102ed7f82",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "5e5c6e7b38db4b8c82e57880eba575ed",
      "bbd446b1e8ed481ab9a4c68a54cd73db",
      "e6ef760faafd437eaaef13c521c74d64",
      "2c8f594d7732403981a037f8c6e353b8",
      "c9481470c3984db3bdac21057a8c0e7c",
      "64fce335b7634dbe94d571ea1bbcd529",
      "f2c714bad4ed4d33a546ea8fcac943e2",
      "355343b297264836b4d7ef50751e5080"
     ]
    },
    "id": "24454aeb-9e3e-4954-ab70-647102ed7f82",
    "outputId": "c80a65dd-08b7-452c-851e-975e49b9e636"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5c6e7b38db4b8c82e57880eba575ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd446b1e8ed481ab9a4c68a54cd73db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ef760faafd437eaaef13c521c74d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8f594d7732403981a037f8c6e353b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9481470c3984db3bdac21057a8c0e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fce335b7634dbe94d571ea1bbcd529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c714bad4ed4d33a546ea8fcac943e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355343b297264836b4d7ef50751e5080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bge = \"local:BAAI/bge-small-en\"\n",
    "bge_val_results = evaluate(val_dataset, bge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da27e48-1c90-4994-aac4-96b5b1638647",
   "metadata": {
    "id": "2da27e48-1c90-4994-aac4-96b5b1638647"
   },
   "outputs": [],
   "source": [
    "df_bge = pd.DataFrame(bge_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc4fe0-b240-4c15-9b2d-a4c79f9aaac2",
   "metadata": {
    "id": "3ddc4fe0-b240-4c15-9b2d-a4c79f9aaac2",
    "outputId": "bd06efc6-7221-45b5-d218-b45ede5f15d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8067915690866511"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_bge = df_bge[\"is_hit\"].mean()\n",
    "hit_rate_bge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd87550-f547-4b8b-b21a-f72b355e2cd7",
   "metadata": {
    "id": "1fd87550-f547-4b8b-b21a-f72b355e2cd7"
   },
   "source": [
    "### Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402dd440-1934-4778-8ff5-28e15cf1f2d3",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "41c6a270908f4ef5b8d87f139f8aa5ce",
      "1f451939dc004748b26a652b0509cbdf"
     ]
    },
    "id": "402dd440-1934-4778-8ff5-28e15cf1f2d3",
    "outputId": "58bc1881-06c7-409d-aa2d-ecb9ee603159"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c6a270908f4ef5b8d87f139f8aa5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f451939dc004748b26a652b0509cbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetuned = \"local:test_model\"\n",
    "val_results_finetuned = evaluate(val_dataset, finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd24643-17cb-4773-a535-77f3f8fa2d48",
   "metadata": {
    "id": "ffd24643-17cb-4773-a535-77f3f8fa2d48"
   },
   "outputs": [],
   "source": [
    "df_finetuned = pd.DataFrame(val_results_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1dccd1-bbd4-427f-a520-b1011643d83b",
   "metadata": {
    "id": "ec1dccd1-bbd4-427f-a520-b1011643d83b",
    "outputId": "b683badb-5c2b-4562-d103-05dbe992c800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8512880562060889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_finetuned = df_finetuned[\"is_hit\"].mean()\n",
    "hit_rate_finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc290bc-5cc3-4ee4-b8ab-e68371441643",
   "metadata": {
    "id": "fbc290bc-5cc3-4ee4-b8ab-e68371441643"
   },
   "source": [
    "### Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f906a11-6a95-4f10-9069-140bf5a56246",
   "metadata": {
    "id": "6f906a11-6a95-4f10-9069-140bf5a56246"
   },
   "source": [
    "#### Hit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fbe3c-2843-4bab-bb5c-16027fc5564b",
   "metadata": {
    "id": "705fbe3c-2843-4bab-bb5c-16027fc5564b"
   },
   "outputs": [],
   "source": [
    "df_ada[\"model\"] = \"ada\"\n",
    "df_bge[\"model\"] = \"bge\"\n",
    "df_finetuned[\"model\"] = \"fine_tuned\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc363c-cd07-4dab-916e-1618d16d1254",
   "metadata": {
    "id": "bebc363c-cd07-4dab-916e-1618d16d1254"
   },
   "source": [
    "We can see that fine-tuning our small open-source embedding model drastically improve its retrieval quality (even approaching the quality of the proprietary OpenAI embedding)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f38b4b-1b40-42da-a054-ea9593d3e602",
   "metadata": {
    "id": "57f38b4b-1b40-42da-a054-ea9593d3e602",
    "outputId": "79ff7056-49c3-4da2-ce47-54539a4fa738"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.896956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bge</th>\n",
       "      <td>0.806792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_tuned</th>\n",
       "      <td>0.851288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              is_hit\n",
       "model               \n",
       "ada         0.896956\n",
       "bge         0.806792\n",
       "fine_tuned  0.851288"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat([df_ada, df_bge, df_finetuned])\n",
    "df_all.groupby(\"model\").mean(\"is_hit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3b1c0-f1f8-4dc8-9787-7a42943e96ab",
   "metadata": {
    "id": "21a3b1c0-f1f8-4dc8-9787-7a42943e96ab"
   },
   "outputs": [],
   "source": [
    "def build_nodes(filepath):\n",
    "\n",
    "    reader = SimpleDirectoryReader(input_files=[filepath])\n",
    "    docs = reader.load_data()\n",
    "    parser = SimpleNodeParser.from_defaults()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=True)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a7cdb-1756-4971-99d4-19b5044499c5",
   "metadata": {
    "id": "3f9a7cdb-1756-4971-99d4-19b5044499c5"
   },
   "outputs": [],
   "source": [
    "def build_index(nodes, embed_model):\n",
    "    index = VectorStoreIndex(\n",
    "        nodes, embed_model=embed_model, show_progress=True\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32deba01-3d0c-440b-9c80-afca9c1fce5b",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "ea1dea0aa9c94de48f33f28700db0bef"
     ]
    },
    "id": "32deba01-3d0c-440b-9c80-afca9c1fce5b",
    "outputId": "e153a584-a9f4-48b0-8a64-4c04b8a32e76"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1dea0aa9c94de48f33f28700db0bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = build_nodes(\"./data/10k/uber_2021.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6547828-173a-4036-8718-3fd6fe2aa766",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a7a3751419f34ea88c901c369c38b389",
      "1b81dd69f2654cf6b6069275bf1e3afa",
      "d3d30838722e4f93a6b91ce23278c92e"
     ]
    },
    "id": "e6547828-173a-4036-8718-3fd6fe2aa766",
    "outputId": "d23a7331-21ce-4baa-f5d6-c1092782c0c5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a3751419f34ea88c901c369c38b389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b81dd69f2654cf6b6069275bf1e3afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d30838722e4f93a6b91ce23278c92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetuned_embed_index = build_index(nodes, \"local:test_model\")\n",
    "base_embed_index = build_index(nodes, \"local:BAAI/bge-small-en\")\n",
    "openai_embed_index = build_index(nodes, ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452ad9d-2610-46f5-a377-d367bc020cdd",
   "metadata": {
    "id": "3452ad9d-2610-46f5-a377-d367bc020cdd"
   },
   "outputs": [],
   "source": [
    "finetuned_embed_qe = finetuned_embed_index.as_query_engine(similarity_top_k=2)\n",
    "base_embed_qe = base_embed_index.as_query_engine(similarity_top_k=2)\n",
    "openai_embed_qe = openai_embed_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015676fa-5868-4645-85c3-9a90598872de",
   "metadata": {
    "id": "015676fa-5868-4645-85c3-9a90598872de"
   },
   "outputs": [],
   "source": [
    "query = \"what is the revenue of uber?\"\n",
    "response1 = finetuned_embed_qe.query(query)\n",
    "response2 = base_embed_qe.query(query)\n",
    "response3 = openai_embed_qe.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dea63c-1b6a-4745-9204-c07ecfc3af75",
   "metadata": {
    "id": "98dea63c-1b6a-4745-9204-c07ecfc3af75"
   },
   "outputs": [],
   "source": [
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a56a9-73e1-4cb9-8170-4a7f49956c08",
   "metadata": {
    "id": "be9a56a9-73e1-4cb9-8170-4a7f49956c08"
   },
   "outputs": [],
   "source": [
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b5fc5-324b-4750-8f81-916f970a2de3",
   "metadata": {
    "id": "350b5fc5-324b-4750-8f81-916f970a2de3"
   },
   "outputs": [],
   "source": [
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a253e93e-cb43-4a95-b48c-7e0dfda32e2c",
   "metadata": {
    "id": "a253e93e-cb43-4a95-b48c-7e0dfda32e2c"
   },
   "outputs": [],
   "source": [
    "for node in response1.source_nodes:\n",
    "    print(\"NODE\")\n",
    "    print(node.get_text())\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06821d0e-871f-4bb8-a748-6ade954fa839",
   "metadata": {
    "id": "06821d0e-871f-4bb8-a748-6ade954fa839"
   },
   "outputs": [],
   "source": [
    "for node in response2.source_nodes:\n",
    "    print(\"NODE\")\n",
    "    print(node.get_text())\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5868fa7-23a5-4d62-9964-f0d2bb324b88",
   "metadata": {
    "id": "b5868fa7-23a5-4d62-9964-f0d2bb324b88"
   },
   "outputs": [],
   "source": [
    "for node in response3.source_nodes:\n",
    "    print(\"NODE\")\n",
    "    print(node.get_text())\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1afe5-cbae-4322-a659-47e5ff240cb3",
   "metadata": {
    "id": "21b1afe5-cbae-4322-a659-47e5ff240cb3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "18H0n6MljJc9TwAuvHoLD4HgjlLBkeQnv",
     "timestamp": 1702793862401
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
