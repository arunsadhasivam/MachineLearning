Steps in fineTuning:
====================

![image](https://github.com/user-attachments/assets/8c1f76ab-8a64-4561-9d92-f19d95d79fcf)


Step 1 : data Gathering and Preprocessing:
==========================================


DataSet Collection:
====================

<p><details><summary>1)High Quality and Diverse Dataset created by skilled Human annotators:</summary>

1)High Quality and Diverse Dataset created by skilled Human annotators:
=========================================================================

   ![image](https://github.com/user-attachments/assets/9c117161-ff2f-46fe-bff3-178255e43be8)

     - instruction fine tuning the data is primarily anontated by skilled humans, where 
       company **hires people to come up with creative questions**, instructions and input - corresponding output.
     - for e.g a human can be tasked with "explain a black hole - like explain to five year old". the Human is
       tasked for this need to be good in physics and english. Then only he can provide the appropriate response.
     - A large amount of such data is gathered and annotated with the order of examples being in 10's of thousand(10 power 10)
     - Now these instrcutions datasets are used to fine tune the base model where the model learns to understand the
       instructions as a human.
     - This data helps the model to align with the format of interacting with the human to be useful of chatgpt or conversation.
     - Example of such data are LIMA, OpenAssistant Dataset, No Robots Datasets.


</details></p>


<p><details><summary>2)LLM Assisted Data Collection:</summary>

2)LLM Assisted Data Collection:
================================

![image](https://github.com/user-attachments/assets/312eb3cf-04d4-42ea-8bed-65111edb63f6)

      - it is used to use Large Language Model itself to generate language generation.
      - here powerful model such as GPT-4 are often used.
      - instruct aligning model with self - generated instructions - reference this article.
      - start with seed instructions, use llm to generate instructions.
      - can use prompt template or llm to generate instructions and input /output pairs.
</details></p>


<p><details><summary>3)External Databases:</summary>

3)External Databases:
=======================

![image](https://github.com/user-attachments/assets/f7df411f-9f4e-4eb0-a2e3-1d9176abfd12)

     - transcribed customer support conversations, meetings, podcasts


</details></p>


 
   
Remember to consider:
=======================

1.quality:
=========

   - LIMA paper highlight the importance of high quality instructions and diverse instructions samples
     to get good performance with minimal no of sample.
   - Idea is to avoid the garbage in -> garbage out phylosophy.

2.quanity:
==========

    - more the quanity but quality is better.
    
3.Diversity:
============

    - diverse tasks enable generalization and serendipity.
    - for e.g in one of hands of exercise " synthetic datasets of short instructions and output" because of which
      the model often generates short response. due to lack of diversity of long response the model is limited in 
      capability.
4.source:
=========

![image](https://github.com/user-attachments/assets/4eed3937-77ae-4800-8552-b90a3c81ace7)

    - usually human annotated data is the gold standard.
    - however many recents work are relying on more more synthetic datasets which are
      generated by llm.
     - however llm generated datas has certain patterns which can hinder model training.


 


    
3)Data Collection pipeline:
===========================

   - First step is to Collect instruction in the form of (instruction, input  and output) tuples
   - Next step is to format the samples by adding tokens to delimit whether following text is a instruction or
     whether it is user input or assistance response.
   - Then these different parts which are delimited by special tokens are concatenated to get the final response.
   - Then the final steps is to create test/train split - to measure the model performance.
   
      ![image](https://github.com/user-attachments/assets/ea9b9be1-7444-4dae-b6bf-de2cfeffb9fa)

    
